# Home

LLMeter is a pure-python library for simple latency and throughput testing of large language models (LLMs) and applications that use them.

It's designed to be lightweight to install; straightforward to run standard tests; and versatile to integrate - whether in notebooks, CI/CD, or other workflows.


## Key features

✅ Measure a wide range of LLMs and agents - including a range of Cloud providers and self-hosted models

✅ Quantify how prompt length, output length, and concurrent request count affect latency - with pre-built high-level experiments

✅ Simple, modular runner and result APIs for defining your own experiments and custom analyses

✅ Lightweight and straightforward to install on a range of environments


---

<div class="grid cards" markdown>

-   🚀 __Getting started__

    ---

    Install and try out LLMeter

    [:octicons-arrow-right-24: User Guide](user_guide)

-   🎯 __Built-in endpoint types__

    ---

    Connect to local or Cloud LLMs

    [:octicons-arrow-right-24: Endpoints](user_guide/connect_endpoints/)

-   ✏️ __Diving deeper__

    ---

    Best-practices and tips for customizing your experiments

    [:octicons-arrow-right-24: User Guide](user_guide/custom_analytics/)

-   :material-github:{ .lg .middle } __Contribute__

    ---
    Review the contributing guidelines to get started!

    [:octicons-arrow-right-24: GitHub](https://github.com/awslabs/llmeter/blob/main/CONTRIBUTING.md)

</div>
